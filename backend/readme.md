# Passively Synchronizing Eventual-Consistency Storage

不依赖中心化的数据同步服务，要同步数据可以将数据目录设置到同步盘

## 选型

用 sqlite 持久化数据，用日志跟踪最近操作

- 日志让多机可以并发操作不同的key。但同一个key，要确保操作的先后顺序，由此需要解决多机的时间同步问题（以用户最后一次操作为准，但还是可能有脏写）
- 组合 sqlite 查询（持久数据）和在内存中维护易于查询的数据结构（近期数据）

## 数据冲突

实际上，由于多机时间同步是不可能的(必须要有一个 modulator)，并且无法解决脏写，一般存储引擎都是单实例写，多实例读的模式

在我们多机写, 多机读的场景下, 特制定以下允许冲突的存储模式：

所有机器共享同一个 sqlite db 文件。

每个机器一个 wal 文件，该文件有与机器名相同的文件名，但还有一个唯一 id 号

每个机器只写自己的 wal 文件，每个 key 从版本 0 开始，每次操作也分配一个版本号，为基于的版本号+1，每次操作还有一个全局唯一的 id 号

如果同一个 key 从某一次操作开始，出现了多个版本号序列，就说明该 key 冲突，需要用户手动选择保留哪个版本，此时，就在解决冲突的机器执行操作：保留版本x(x为操作 id 号)

如果重复解决冲突, 即同时执行了保留版本x1, 和保留版本x2, 那该将 key 退回到冲突状态, 直到冲突解决, 所有机器同步到最新数据

## 持久化

持久化即将日志文件持久化至 sqlite db 文件

在多机情形下，我们需要协调由谁来负责持久化操作，以避免产生多个 db 文件造成文件冲突

### 仅限单机操作

我们无法保证仅限单机操作，考虑多机系统中有一台机器长期离线，那么它与其他机器在这段时间形成了两个独立的分区，它可以把自己看成唯一的参与者，从而和另一个分区并行做出任何决策

### 多机可操作

首先，考虑一下对于每台机器，只要条件满足就持久化是否可行

持久化的条件暂定为日志文件达到一定规模，这使得多台机器同时满足条件的概率降低

这种情况，依然存在两台机器同时执行持久化（网络分区时必然存在），因此，我们需要允许创建多个 sqlite db 文件，不过不用担心文件会持续增多，任何一个实例启动时，根据某种确定的规则删除多余的 sqlite db 文件即可

#### 日志剪裁

日志剪裁即对于已经持久化的操作版本以前的条目，可以全部删除以减少日志文件大小，节省空间、提高性能

删除多余的 sqlite db 文件将影响日志剪裁，由于单机不知道自己看到的 sqlite db 文件什么时候会被删，所以不敢贸然进行日志剪裁操作

一个解决方案如下：

删除 sqlite db 文件时需要确保安全性，如果无法安全地删除它，就在下次触发持久化时合并多个 sqlite db 文件（其实就是重新持久化一次）。

重新持久化后，需要删除旧文件，此时要注意正在使用的文件被删除问题。

### 冲突 key 的持久化

每个 key 在持久化时都保存它上次持久化的版本 id 和本次最新的版本 id

这样就能区分一个 key 的冲突版本

但存在这样的情况, key1 在机器 A 持久化一次，在机器 B 持久化一次，而机器 A 上的 key1 版本小于机器 B 上的key1。最后，在 db 文件合并时，会将这两个 key 视为冲突的版本。

为解决这个问题，持久化一个 key 需要将它**所有**版本 id 保存下来，作为判断新旧版本的依据

单靠 { key, value, id } 的组合无法判断一个 key 是另一个 key 的老版本而不是冲突版本

### 手动操作

### 类 git 方式

每个机器维护独立的目录，里面包含 sqlite 数据文件和日志，实例启动时，读取自己的目录，然后尝试合并其他机器的数据文件

合并完成，写入sqlite，记录合并时所有机器版本号

合并过程中：
- 无冲突，直接写入
- 有冲突，保留自己的修改，保留其他机器的修改

不立即解决冲突：

写入冲突的版本，本机版本依然可以操作，也可以随时解决冲突

添加机器：

创建空目录，做一次合并即可

其他:
一个表一个文件, 字段级别操作
以持久化文件为主, 日志仅用于合并
日志也作为wal，用以恢复数据（数据写操作先写日志，再写内存，最后落sqlite，sqlite写失败也不要紧）

再其他:
每个参与者都要公开已同步日志位置, 便于其他参与者剪裁自己的日志(取所有参与者最久远同步位置作为剪裁终点)
    1. 我们让新参与者的同步位置至少与一个现有参与者相同(做不到), 即使该参与者从来没有上线, 也可以剪裁
    2. 让用户确认所有参与者列表以确保没有未上线的?
    
怎么保存冲突key

日志格式可以有多种, 定义日志接口

怎么 diff 日志

有机器永久离线，导致其他机器无法剪裁日志怎么办？
用户可以管理（删除）机器，或者离线时间过长的机器自动降级为单向同步（可以同步给其他机器，不可以从其他机器同步）

日志组织为多个小文件，提高可靠性，也方便剪裁

持久化失败不再持久化, 待重试

不定期创造日志文件同步条件
    日志文件同步条件是什么

处理冲突，用deny代替accept

支持保存前预览

每个key，记录创建者

用户可以指定计算机名，程序要验证数据文件属于该计算机

新参与者加入时，随机复制一个旧参与者

自然冲突处理(即拒绝与自身相冲突的修改)作为可选项?

需要结合其他参与者同步我方的状态判断冲突

分为先行同步和后发同步，找到A中还没执行的日志
这个过程叫做patch
存储叫做passively synchronizing eventual-consistency storage
解决冲突的方法是删除，这样才能多机工作

已同步到的每个参与者最后一条记录的时间

同步：
    假设网络中有参与者A，参与者B
    最初（时刻t0）参与者A，参与者B都与对方是同步状态（因为两者都是空的）；新加入的参与者也保证与现有参与者是同步状态
    以后每次A同步B的时刻，保证A与B是同步的（B与A不一定同步）
    在时刻tx，参与者A欲同步参与者B内容，此时有两种情况
    1. t0后，B没有同步过A
    2. t0后，B已经同步过A
    第一种情况，对A来说就是先行同步；第二种情况，则是后发同步
    
    先行同步：
    只需要计算时刻t0-tx，参与者A，参与者B的修改情况，若B的修改与A不相关，则合入B修改至A；若相关，则合入其中不相关的修改，记录相关（冲突）的修改
    
    后发同步：
    此时，参与者A需要了解参与者B已同步的状态，即参与者B在t0-tx中已在t1时刻同步过参与者A，参与者A需要假定从t0开始做一遍t0-t1时刻的同步，就得到了t1时刻B的状态（执行了一样的日志，暂不证明，认为A-B状态相同），然后重做t1时刻后B的修改，就得到了B最新的状态（Bnow），然后再将A在t1时刻后的修改合入Bnow，就得到了A合入B的状态，而A合入B的状态应该与B合入A的状态相等，所以我们将从t0得到Bnow的所有A没做的修改提交到A，就得到了B合入了A的状态
    
    超过2个参与者：
    在2个参与者中，我们将需要合入到A的操作称作patch，多机情形，需要计算出A-B的patch，A-C的patch，...，将所有patch合并，如果所有patch不相关，则直接提交进A，否则，记录冲突状态。

    冲突：
    遇到冲突时，支持记录删除一个版本的操作，如A与B都修改了key1，支持删除一个版本来解决冲突，但删除操作要关联key的名字以及该key冲突时的日志id，若不知晓删除操作的参与者又对已删除版本做了更新，由于最新日志id已经改变，则删除无效（冲突继续存在）

    一些问题：
    t1时刻B同步A有冲突，A做t0-t1时刻的合并会有冲突吗
    基于A，B所做操作判断冲突，能根据最终值比较来判断冲突吗
    
    本KV数据库, 需要支持哪些操作:
    增: 和wal一起使用的情况下, 无法支持
    删: 支持
    查: 支持
    改: 支持

    以上同步有个比较严重的问题, B和D同时修改某key, B先合入A, D后合入A, 冲突消失。原因是不同机器的日志之间没有维持精确的时间先后顺序（只有同步时间可以作为操作的先后顺序依据）
    
    还有在解决冲突中，如果删除操作先同步至A，冲突的key才到A，又怎么办，一个方法是将删除记录单独建表

每个key都是一棵树：
    每个key的修改记录链接其上一条记录，所有修改记录构成一棵树，每个叶子节点就形成一个版本
    
    每个机器都可以基于自身的同步情况，建设这棵树，在客观上以及对于每个机器最终，都能得到一棵完整的树
    
    sqlite存的是本机器跟踪的分叉最新值
    
    一条日志允许多个操作，以便一次性（原子地）删除多条分叉
    
    问题：
        同步时，base结点不存在？
        日志如何剪裁？
        <del>在每台机器上建一个完整的树？</del>
        
        sqlite保存目前已知的叶子情况，并且标注哪个版本是本机跟踪的
       <del>
        合并日志时，若一个节点前向节点在sqlite找不到，就说明：
        1. 它是未来节点，暂不合并
        2. 它是新建节点，需要能识别新建节点。新建节点直接合并
        </del>
        
    上次同步开始,轮流遍历日志建树
    用map重建树，找出上次同步产生的key列表
    <del>所有叶子结点都同步到了其他机器，就可以剪裁了？</del>
    
    同步状态就是叶子叶子结点全部入库，因为只使用叶子结点
    尽力同步，有可能因为一个key卡死

    <del>同步定义是一棵部分树的叶子，新的结点只会从这些叶子结点开始，或者创建新树，同步过的日志可以删除</del>
    
    标记本节点为部分同步状态
    机器永久离线？那就会卡死同步
    sqlite记录的是上次同步所有叶子节点
    同步后A更新了叶子节点？不影响
    
    正式同步方案：
    <del>
    设有A-E五台机器，最初，A与机器B-E处于同步状态（都是空的）
    新加入的机器由于也是空的，A与它也是同步状态
    
    同步状态是指：对于A自己的最新日志a0，加上获取到的B-E机器b0-e0之前的日志所构成的树，其所有叶子节点已存储到A的sqlite中。下次再同步时，除了新创建的树（key），所有节点仅会引用sqlite中的这些叶子节点（还是会引用非叶结点的）
    </del>
    
    
    
    <del>需要支持直接合并其他机器(合并sqlite？)</del>
    
    <del>
    每个机器同步后公布已获取其他机器的日志位置，以剪裁日志（未注册机器会有问题，即拷贝了现有机器就下线的，怎么处理很久未活动机器）
    </del>
    
    
    从后往前染色（从日志后面往前转移节点），这是建树的方法
    
    <del>所有部分树交集前面的日志可以跳过</del>
    有一个机器一直不同步？就剪裁不了日志
    
    提示每个peer的最后同步内容

<hr>
    
树方案最终版：

日志：
日志顺序存储对每个key的操作，每一个操作的格式如下：
操作类型，key，value，gid，上一条日志gid，上一条日志运行完的值，seq，产生本操作机器名，产生上一操作机器名

操作类型有：
modify，del，discard
也可以增加其他类型

key即操作的对象，value为对应的值
每条日志会生成一个全局唯一的gid，并且会链接到上一条日志

一个key刚创建第一条日志seq为0，链接到它的日志seq=seq+1
每一条日志可以记录多个操作

单机情况，每次对key操作，都基于并链接到上一条最新日志（如果有的话），该key所有日志形成一条链，顺序运行这条链所有日志即可得出key最新状态
多机情况，每个机器都可以对key操作，并可以链接到上一条日志（不一定是最新的），客观上，每个机器对key操作都是在新增节点，所有节点
形成一棵树（或多棵树），从该树根节点出发运行至该树每个叶子节点都得出该key的一个冲突版本
多机情况，如果树有分叉且值不同，可以手动解决冲突，方法是在不想要的分支末端增加discard操作，直至这棵树只剩下一个有效分支

总结：
每个机器都有自己独立的日志文件，日志中包含操作节点，所有机器的日志记录的所有节点客观上可以构建出多棵树（每个key对应一棵树或多棵树），而创建节点这个操作本身是不会有冲突的，为一个父节点创建多少子节点都可以，因此，在日志层面，多机不会有冲突

任意机器可以获得其他机器创建的节点信息，取决于获得信息的完整度，它可以还原出多棵完整的树或部分树，但最终，它一定可以获取目前为止，所有节点的信息（亦即当前客观的、完整的树），从而达到最终一致性

sqlite：

sqlite用于存储本机当前已知多个key部分树（或完整树）所有叶子节点的值，存储的字段有
key，value，seq，gid，prev_gid，is_discarded，is_main，machine_id, prev_machine_id

- key和树是一对多的，代表这是哪个树叶子节点的值
- value即对应的值
- seq叶子节点日志的seq
- gid为叶子节点日志的gid
- prev_gid即叶子节点父节点gid
- is_discarded代表该叶子节点无效（在解决冲突时执行了discard操作）
- is_main表示这是本机跟踪的分支
- machine_id表示产生本分支节点的机器名
- prev_machine_id表示产生父节点的机器名

当sqlite已存储当前已知部分树或完整树的叶子节点的值，这些树完整的结构（中间节点是怎么样的）就不重要了，实质上就是，旧的操作日志就不重要了

sqlite中还记录上一次同步其他机器的情况，记录其他每个机器的：
机器名-上次同步最后一条日志的gid

同步时，从每台机器上次同步的最后一条日志开始，遍历新的日志，扩展本机已知的树，该过程会参考sqlite中存储的所有叶子节点，将新的操作日志分为以下四种情况：

1. seq==0: 表示要创建一棵新树
2. seq<=某key所有叶子节点的seq，说明是该key的又一分叉节点
   1. 如果日志的上一日志机器名为本机，将该节点当成新的叶子节点
   2. 否则，说明该节点父节点不可知，最终会知道
3. seq==某叶子节点seq+1，分两种情况
   1. prev_gid==叶子节点gid，说明是更新的叶子节点
   2. prev_gid!=叶子节点gid，说明该节点父节点还不可知，最终会知道
4. seq>所有叶子节点的seq+1，说明是叶子节点的未来节点，所属日志暂停遍历，直到获得叶子节点到未来节点的中间节点

日志遍历完成，sqlite中部分key的叶子节点更新为新叶子节点，或创建了新key，有的日志运行到了最新位置，有的由于存在中间节点未知的未来节点，尚未运行到最新位置，等待下次同步，但最终，如果所有机器网络正常，所有机器日志在本机都会运行到最新位置
最后，记录一下每个机器日志已运行的位置情况

日志的剪裁：

每台机器同步其他机器的情况（其他机器名--日志位置）都向其他机器公开，假设本机要剪裁日志，统计其他机器记录的本机日志已同步位置，找出最老的那一条，这之前的日志就可以删除了。

其他：

能否发展为通用分布式存储
可以用gorm的migrate？

#### 降低数据同步频率和数据量
